{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rekall\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])\n",
    "assert os.environ[\"CONDA_DEFAULT_ENV\"] == \"rekall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the video metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'filename': 'stanford/2019/5/46392/DA0036RI.IMG/0036RI01.mp4',\n",
       " 'num_frames': '3827',\n",
       " 'fps': 59.94005994005994,\n",
       " 'width': 320,\n",
       " 'height': 240}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/share/pi/cleemess/danfu/2019-05-good-mp4s-metadata.json') as f:\n",
    "    video_metadata = list(json.load(f))\n",
    "video_metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 423 videos with metadata\n"
     ]
    }
   ],
   "source": [
    "print('There are {} videos with metadata'.format(len(video_metadata)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, SpatialType_Caption\n",
    "# from vgrid_jupyter import VGridWidget\n",
    "# from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D\n",
    "from glob import glob\n",
    "import eeghdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out videos that we can't find the annotation file for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found annotations for 221 of the 423 videos.\n"
     ]
    }
   ],
   "source": [
    "annotation_exists_count = 0\n",
    "for i, vm in enumerate(video_metadata):\n",
    "    # Convert video filename to annotation filename\n",
    "#     vm[\"fps\"] = 29.97\n",
    "    vm[\"filename\"] = vm[\"filename\"].replace(\"stanford/\",\"\")\n",
    "    fn = vm[\"filename\"]\n",
    "    intermediate = fn.split(\"/\")[-1]\n",
    "    num = int(intermediate[-6:-4])\n",
    "    parent = \"/\".join(fn.split(\"/\")[:-2])\n",
    "    img_folder = fn.split(\"/\")[-2][:-4]\n",
    "    annotation_file = img_folder + f\"_1-{num+1}+.h5\"\n",
    "    full_fn = os.path.join(\"/share/pi/cleemess/file-conversion-pipeline\", parent, annotation_file)\n",
    "    vm[\"annotation_filename\"] = full_fn if os.path.exists(full_fn) else None\n",
    "    annotation_exists_count += int(os.path.exists(full_fn))\n",
    "print(f\"We found annotations for {annotation_exists_count} of the {len(video_metadata)} videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter out videos that aren't broken up into pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 of the 423 videos are the only video in their directory (so this video is not a part of a sequence of broken up clips).\n"
     ]
    }
   ],
   "source": [
    "only_video_count = 0\n",
    "for vm in video_metadata:\n",
    "    fn = vm[\"filename\"]\n",
    "    parent = os.path.join(\"/share/pi/cleemess/file-conversion-pipeline\", \"/\".join(fn.split(\"/\")[:-1]))\n",
    "    fn = fn.split(\"/\")[-1]\n",
    "    other_vids = glob(os.path.join(parent, fn[:-6]) + \"*.mp4\")\n",
    "    vm[\"only_video\"] = len(other_vids) == 1\n",
    "    only_video_count += int(len(other_vids) == 1)\n",
    "print(f\"{only_video_count} of the {len(video_metadata)} videos are the only video in their directory (so this video is not a part of a sequence of broken up clips).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize videos with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgrid import VGridSpec, VideoMetadata, VideoBlockFormat, SpatialType_Caption\n",
    "from vgrid_jupyter import VGridWidget\n",
    "from rekall import Interval, IntervalSet, IntervalSetMapping, Bounds3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the video metadata in a special object for use in VGrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata_wrapper = [\n",
    "    VideoMetadata(\n",
    "        vm[\"filename\"], id=str(id), fps=vm[\"fps\"],\n",
    "        num_frames=int(vm[\"num_frames\"]), width=vm[\"width\"], height=vm[\"height\"])\n",
    "    for id, vm in enumerate(video_metadata)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a  function that filters the videos for annotations that contain the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clips_for_keyword(keyword):\n",
    "    ism = {}\n",
    "    for vm in video_metadata:\n",
    "        if not vm[\"annotation_filename\"] or not vm[\"only_video\"]:\n",
    "            continue\n",
    "        h5 = eeghdf.Eeghdf(vm[\"annotation_filename\"])\n",
    "        starts = [start / 10**7 for start in h5._annotation_start100ns]\n",
    "        texts = h5._annotation_text\n",
    "\n",
    "        if not keyword or any(keyword.lower() in text.lower() for text in texts):\n",
    "            interval_set = IntervalSet([\n",
    "                    Interval(\n",
    "                        Bounds3D(start , start + 5),\n",
    "                        {\n",
    "                            'spatial_type': SpatialType_Caption(text + \"\\n\"),\n",
    "                            'metadata': {}\n",
    "                        }\n",
    "                    ) for start, text in zip(starts, texts)\n",
    "                ]) \n",
    "            ism[vm[\"id\"]] = interval_set\n",
    "\n",
    "    vgrid_spec = VGridSpec(\n",
    "        video_meta=video_metadata_wrapper,\n",
    "        vis_format=VideoBlockFormat(imaps=[('bboxes', ism)]),\n",
    "        video_endpoint='http://localhost:8080'\n",
    "    )\n",
    "    return VGridWidget(vgrid_spec=vgrid_spec.to_json_compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the function to visualize clips with seizures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f8b674350c4843a0f1f2d034a8fdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VGridWidget(vgrid_spec={'compressed': True, 'data': b'x\\x9c\\xed]ko\\x1c\\xb7\\x92\\xfd+\\x86>-\\xb0\\x9b\\x11\\xdf\\x8f|â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_clips_for_keyword(\"seizure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the videos are not as good, but the first video clearly shows a seizure at the annotation's time stamp. \n",
    "\n",
    "The final video also shows a seizure at the 9:40 mark, not where the annotation start time marker is though.\n",
    "\n",
    "The other videos don't seem like seizures to me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
